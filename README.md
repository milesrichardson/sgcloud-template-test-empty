# Sample Splitgraph Cloud project

Welcome to the sample Splitgraph Cloud project that we generated for your chosen data sources.

This project contains:

  * [`splitgraph.yml`](./splitgraph.yml): defines live and ingested data sources as well as other
    metadata for your data catalog.
  * [`splitgraph.credentials.yml`](./splitgraph.credentials.yml): defines credentials to your 
    data sources
  * [`build.moveme.yml`](./build.moveme.yml): GitHub Action that runs ingestion / metadata upload
    for all sources:
    * Adds data sources supporting "live" querying (PostgreSQL, MySQL, Elasticsearch, CSV-in-S3) to
      Splitgraph without ingestion, letting you query them at source
    * Runs a "sync" action for other data sources (SaaS etc) to load their data to Splitgraph  
    * Optionally, also runs a dbt project at the end of ingestion to build models.
    
All built repositories are going to be private to your account. You can manage access settings in
the UI by going to https://splitgraph.com/namespace/repository. 

## Required setup

Before you can run this project from GitHub Action, you need to perform a few extra setup steps.

### Add credentials to `splitgraph.credentials.yml`

Edit [`splitgraph.credentials.yml`](./splitgraph.credentials.yml) to add required credentials to
your data sources. **DO NOT COMMIT IT!** You'll add the contents of this file as a secret in the
next step.

### Set up GitHub secrets

Go to the [Secrets page](https://github.com/milesrichardson/sgcloud-template-test-empty/settings/secrets/actions/new) for this
repository and create the following secrets:
  
  * `SPLITGRAPH_CREDENTIALS_YML`: contents of the `splitgraph.credentials.yml` with the data source
    credentals that you've edited in the previous step. 
  * `SPLITGRAPH_API_KEY` / `SPLITGRAPH_API_SECRET`: API keys to Splitgraph Cloud (also known as
    "SQL credentials"). You can get them at https://www.splitgraph.com/settings/sql-credentials (or
    your deployment URL if you're on a private deployment).

### Set up GitHub Actions

Because this repository was itself generated by a GitHub Actions job, we can't edit the workflow
files for this repository from within the action. You will need to move the job definition file
([`build.moveme.yml`](./build.moveme.yml)) to `.github/workflows/build.yml`.

Optionally, also delete the `seed.yml` file that was used to generate this project.

### Set up dbt and write the models

If you added dbt to this project, this repository also contains a sample dbt project that references
data from all the datasets you've added to it. See [`dbt_project.yml`](./dbt_project.yml) and the
[`models/staging/sources.yml`](models/staging/sources.yml) file for more information.

Currently, we can't infer the columns and the tables that your data sources will produce at this
project generation time, so this dbt project is here as a rough starting point. To get it working,
you will need to: 
 
* Manually define tables in your sources (see 
  [`models/staging/sources.yml`](models/staging/sources.yml), "tables" sections). You might want
  to run the ingestion GitHub Action once first without the dbt step in order to create the
  repositories on Splitgraph and see their tables and columns.
* Write the actual models that reference the sources using the `source(...)` macros (see 
  `models/staging/(source_name)/source_name.sql` for an example)

## Run the action

By default, the generated action waits for a manual trigger to run. You can trigger the action by
going to https://github.com/milesrichardson/sgcloud-template-test-empty/actions/workflows/build.yml and clicking "Run workflow". 

## Next steps
 
  * Edit the GitHub Action to, for example, add a run schedule
  * Browse the ingested and built datasets at https://splitgraph.com/namespace/repository
  * Connect to Splitgraph with an SQL client (see [the docs](https://www.splitgraph.com/docs/splitgraph-cloud/data-delivery-network)) 
